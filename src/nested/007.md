# **Module 7: Time Series Management for Soil Monitoring**

Design databases for high-frequency sensor data with irregular timestamps, sensor drift, and missing values. Implement automated QA/QC for field-deployed sensors subject to biofouling and extreme conditions.

The course objective is to design and implement resilient, scalable systems for managing high-frequency soil sensor data. This module focuses on the end-to-end engineering of time series pipelines, from database selection and data ingestion to the development of automated QA/QC routines that handle the harsh realities of field deployments, including sensor drift, biofouling, data gaps, and extreme environmental conditions.

This module is a critical component of the **Foundation Phase**, directly addressing the fourth major data stream: field sensors. It builds on the multi-scale architectures from Module 2 and the spatial context from Module 6. The clean, continuous, and quality-assured time series data produced here is the essential fuel for the dynamic foundation models to be developed later, such as **Temporal Convolutional Networks for Soil Monitoring** (Module 55) and **Neural Ordinary Differential Equations for Soil Dynamics** (Module 56).

---

### **Hour 1-2: The Reality of Field Sensor Networks: Chaos & Complexity** ‚õàÔ∏è

**Learning Objectives:**
* Understand the unique challenges of managing high-frequency, autonomous sensor data compared to static lab data.
* Identify the common failure modes in field deployments and their data signatures.
* Map the data flow and potential bottlenecks from a sensor in the ground to a research database.

**Content:**
* **The Data Tsunami**: Calculating the data volume from a network of 100 sensors reporting every 5 minutes for a year. Why this requires a different approach than a spreadsheet.
* **The Rogues' Gallery of Field Problems**:
    * **Biofouling**: How roots, microbes, and insects physically interfere with sensors.
    * **Environmental Extremes**: The impact of freeze-thaw cycles, lightning strikes, and flooding.
    * **The Animal Factor**: From rodents chewing cables to livestock damaging installations.
    * **The Human Element**: Power failures, network outages, and configuration errors.
* **Data Signatures of Failure**: Learning to visually identify the patterns associated with a dying battery (gradual drift), a loose connection (intermittent noise), or a flooded sensor (flat-lining).

**Practical Exercise:**
* You are given raw, uncleaned time series data from a real-world soil sensor network (e.g., from the NEON or LTER network).
* Visually inspect the data using Python's `matplotlib` or `plotly`.
* Create an "issue log" by taking screenshots of data anomalies and hypothesizing the physical cause of each (e.g., "Sharp drop to zero suggests power loss," "Noisy signal in Sensor B suggests water intrusion").

---

### **Hour 3-4: The Right Tool for the Job: Time Series Databases (TSDB)** ‚è±Ô∏è

**Learning Objectives:**
* Understand why traditional relational databases (like PostgreSQL) are inefficient for time series workloads at scale.
* Master the core concepts and advantages of purpose-built Time Series Databases (TSDBs).
* Design an efficient database schema for a complex soil monitoring network.

**Content:**
* **Relational vs. Time Series**: Comparing query performance for a typical temporal aggregation (e.g., "calculate the daily average temperature for all sensors last year"). Why TSDBs are orders of magnitude faster.
* **Introduction to the Leaders**:
    * **TimescaleDB**: An extension that adds time series power to PostgreSQL, blending familiarity with performance.
    * **InfluxDB**: A popular, standalone TSDB known for its high-speed ingestion and specialized query language (Flux/InfluxQL).
* **Key TSDB Concepts**:
    * **Hypertables & Chunks (TimescaleDB)**: Automatic partitioning of data by time for massive performance gains.
    * **Measurements, Tags, and Fields (InfluxDB)**: A data model that separates metadata (tags) from measured values (fields) for rapid indexing and querying.
* **Schema Design**: Modeling a network with multiple sites, profiles, depths, and measured variables (moisture, temp, EC) using a tag-based approach.

**Database Design Lab:**
* Install PostgreSQL with the TimescaleDB extension.
* Write the SQL Data Definition Language (DDL) to create a hypertable for a soil sensor network.
* The schema must efficiently store data from 50 sites, each with 3 profiles, 5 depths, and 4 variables.
* Justify your choice of `tags` (for metadata like site_id, depth) and `fields` (for the sensor readings).

---

### **Hour 5-6: Ingestion & Temporal Resampling** üì•

**Learning Objectives:**
* Build a robust pipeline to parse and ingest data from common datalogger formats.
* Master the art of temporal resampling to handle irregular data and create standardized time steps.
* Implement bulletproof timezone management.

**Content:**
* **Parsing the Unruly**: Writing parsers for non-standard formats, including multi-header CSVs from Campbell Scientific loggers and JSON payloads from IoT devices.
* **The Resampling Toolkit (Pandas)**: A deep dive into the `.resample()` method.
    * **Downsampling**: Aggregating high-frequency data to a coarser resolution (e.g., 1-minute data to hourly averages, max, min).
    * **Upsampling & Interpolation**: Creating a regular time index from irregular measurements using methods like linear interpolation or forward/backward fill.
* **The Cardinal Sin of Time Series**: Why you **must** convert all incoming timestamps to UTC for storage and only convert to local time for display. We'll explore the chaos caused by daylight saving time.

**Hands-on Lab:**
* Write a Python script using `pandas` to ingest a messy CSV file with irregular timestamps and mixed timezones.
* The script must:
    1.  Correctly parse the timestamps and convert everything to UTC.
    2.  Resample the data to a regular 15-minute interval, calculating the mean for the period.
    3.  Generate a plot comparing the raw, irregular data with the clean, resampled data.

---

### **Hour 7-8: Automated QA/QC I: Rule-Based Flagging & Spike Detection** üö©

**Learning Objectives:**
* Design and implement the first layer of an automated data quality control system.
* Build robust tests for detecting physically implausible values and sudden spikes.
* Create a standardized, multi-level quality flagging system.

**Content:**
* **A Tiered Flagging Schema**: Designing a system (e.g., 0=Unchecked, 1=Good, 2=Suspect, 3=Bad) that can be applied at each stage of the QA/QC process.
* **Rule-Based Checks**:
    * **Gross Range/Plausibility Check**: Defining the physically possible range for each sensor (e.g., soil moisture cannot be > 1.0 v/v).
    * **Rate of Change/Spike Check**: Identifying sudden jumps that are physically unlikely (e.g., soil temperature changing by 5¬∞C in one minute). This is often implemented with a rolling window approach.
* **Persisting Flags**: Storing the quality flags alongside the data in the TSDB, ensuring that raw data is never altered, only annotated.

**Technical Workshop:**
* Write a Python function that takes a pandas Series of sensor data and a set of configuration parameters (min/max plausible values, max rate of change).
* The function should return a corresponding Series of quality flags.
* Apply this function to a noisy dataset and create a plot that color-codes the data points by their assigned quality flag, visually highlighting the detected errors.

---

### **Hour 9-10: Automated QA/QC II: Detecting & Correcting Sensor Drift** üìâ

**Learning Objectives:**
* Understand the physical and chemical causes of sensor calibration drift.
* Implement statistical methods to detect slow, gradual changes in sensor behavior.
* Build a workflow for applying drift corrections based on periodic field calibrations.

**Content:**
* **Why Sensors Lie Over Time**: Exploring the mechanisms of drift, such as the degradation of an electrode's reference solution or the clouding of an optical sensor.
* **Detecting Drift**:
    * **Paired Sensor Comparison**: Comparing a field sensor to a freshly calibrated reference sensor during maintenance visits.
    * **Statistical Drift Detection**: Using methods like the Cumulative Sum (CUSUM) control chart to detect subtle, long-term deviations from expected behavior.
* **Modeling the Correction**: When field calibrations show a sensor has drifted, we can model this drift over time (e.g., with a linear or polynomial function) and apply a time-varying correction to the historical data.
* **The Importance of Provenance**: Storing both the raw data and the drift-corrected data, with a clear audit trail of what correction was applied and when.

**Practical Exercise:**
* You are given a time series from a sensor that is known to be drifting, along with three calibration events where the "true" value was recorded.
* Fit a linear regression between the sensor's readings and the time elapsed.
* Use this regression to calculate a time-varying correction factor.
* Apply the correction to the entire dataset and plot the raw (drifting) data against the corrected data.

---

### **Hour 11-12: Handling Data Gaps: Advanced Imputation** üï≥Ô∏è

**Learning Objectives:**
* Classify different types of missing data and understand why the cause matters.
* Implement more advanced imputation techniques that leverage correlated variables.
* Evaluate the performance of different imputation methods.

**Content:**
* **Why Data is Missing**: Differentiating between Missing Completely at Random (MCAR), Missing at Random (MAR), and Missing Not at Random (MNAR). Why a gap from a lightning strike (MCAR) is different from a sensor failing only in frozen soil (MNAR).
* **Beyond Linear Interpolation**:
    * **Multivariate Imputation**: Using relationships between variables to fill gaps. For example, using a linear model based on air temperature and solar radiation to impute missing surface soil temperature.
    * **Machine Learning Approaches**: Using algorithms like k-Nearest Neighbors or Random Forests for imputation.
* **Validating Your Guess**: Techniques for testing imputation methods by artificially creating gaps in a complete dataset and measuring how well the algorithms reconstruct the known values.

**Imputation Lab:**
* Take a dataset with co-located soil moisture and precipitation data.
* Artificially remove a 24-hour block of soil moisture data.
* Attempt to fill the gap using three methods: linear interpolation, a simple forward-fill, and a linear regression model based on the precipitation data.
* Compare the imputed values from each method to the true, removed values and calculate the Root Mean Square Error (RMSE) for each to determine the best approach.

---

### **Hour 13-14: From Clean Data to Insight: Time Series Feature Engineering** üõ†Ô∏è

**Learning Objectives:**
* Aggregate and transform time series data to extract meaningful environmental signals.
* Perform frequency analysis to identify dominant cycles.
* Create a feature set suitable for training dynamic machine learning models.

**Content:**
* **Temporal Aggregation**: Calculating biologically relevant metrics like growing degree days, cumulative rainfall, or diurnal temperature range.
* **Window Functions**: Using rolling windows to calculate statistics that capture the recent state of the system, such as the 7-day moving average of soil moisture.
* **Frequency Domain**: Using a Fast Fourier Transform (FFT) to decompose a time series into its constituent frequencies, allowing you to quantify the strength of daily and annual cycles.
* **Feature Engineering for ML**: Creating lagged variables (e.g., soil moisture from 24 hours ago) and interaction terms that will be critical inputs for predictive models.

**Analysis Workshop:**
* Using a clean, hourly soil temperature dataset, write a script to:
    1.  Calculate the daily minimum, maximum, and average temperature.
    2.  Calculate the 7-day rolling average.
    3.  Perform an FFT and plot the resulting periodogram to show the dominant 24-hour cycle.

---

### **Hour 15: Capstone: Building a Resilient, Automated Sensor Pipeline** üè≠

**Final Challenge:**
Design and build a complete, production-ready data pipeline that automatically ingests, cleans, and processes data from a network of soil sensors.

**The Input**: A directory of raw, messy, daily CSV files from a network of 10 sensors. The data contains gaps, spikes, drift, and irregular timestamps.

**Your Pipeline Must:**
1.  **Ingest**: Automatically detect and load new daily files.
2.  **Store**: Write the raw data to a TimescaleDB database.
3.  **Clean & Flag**: Resample the data to a regular 1-hour interval. Apply a multi-stage QA/QC process to flag bad data (range checks, spike detection). Store these flags in the database.
4.  **Correct & Impute**: Apply a pre-defined drift correction function to two of the sensors. Impute any remaining data gaps shorter than 6 hours using linear interpolation.
5.  **Publish**: Write the final, clean, analysis-ready data to a new table in the database.
6.  **Visualize**: Create a simple dashboard (e.g., using Grafana or Dash) that plots the raw data, the quality flags, and the final cleaned data for any selected sensor.

**Deliverables:**
* The complete, documented Python pipeline code.
* The SQL schema for the TimescaleDB database.
* A brief report justifying your QA/QC parameter choices and interpreting the results for one sensor, explaining how the cleaning process improved the data's reliability.

**Assessment Criteria:**
* **Automation & Robustness**: The pipeline should run automatically and handle common errors gracefully.
* **Correctness**: The QA/QC and imputation logic must be implemented correctly.
* **Database Design**: The TSDB schema must be efficient and scalable.
* **Clarity & Insight**: The final report and visualization must clearly communicate the value and process of the data cleaning pipeline.