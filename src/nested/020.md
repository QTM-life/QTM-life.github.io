# **Module 20: API Design for Soil Intelligence Services**

Build RESTful and GraphQL APIs that serve model predictions while handling authentication, rate limiting, and usage tracking for agricultural decision support systems.

The course objective is to build and deploy production-grade Application Programming Interfaces (APIs) that serve soil model predictions as reliable, secure, and scalable services. Students will master both RESTful and GraphQL paradigms, implementing essential production features including authentication, rate limiting, and usage tracking. This module provides the critical link between backend models and front-end agricultural decision support systems.

This is the capstone module of the **Foundation Phase**. It's the "front door" to all the data and models we have painstakingly engineered in Modules 1-19. While other modules created the assets, this one makes them usable by the outside world. The APIs designed here will be the primary mechanism for the applications in the **Deployment & Applications Phase** (e.g., mobile apps, farm management platforms) to consume the intelligence generated by our foundation models.

---

### **Hour 1-2: From Notebook to Service: The "Why" of APIs** üí°

**Learning Objectives:**
* Articulate why a trained model file (`.pkl`, `.pt`) is not a product and how an API turns it into a usable service.
* Understand the client-server architecture and the role of an API as a formal contract.
* Design the request and response data structures for a soil intelligence service.

**Content:**
* **The Last Mile Problem**: A data scientist's Jupyter notebook is a dead-end for a farmer's app, a tractor's guidance system, or a web dashboard. We need a live, running service that can accept requests and return predictions over a network.
* **The API as a Contract**: An API defines the precise rules of engagement: what endpoint to call, what data to send, what format to expect in return. It decouples the front-end application from the back-end model, so they can evolve independently.
* **Core Design Principles**:
    * **Statelessness**: Every request should contain all the information needed to process it.
    * **Clear Naming**: Resources should be intuitive nouns (e.g., `/samples/`, `/predictions/`).
    * **Standard Response Codes**: Using HTTP status codes correctly (`200 OK`, `400 Bad Request`, `404 Not Found`, `500 Server Error`).

**Design Workshop:**
* For three of the foundation model concepts (e.g., `SpectraInterpreter-Soil`, `CompactionRisk`, `NitrogenCycler`), students will design the API contract.
* In a markdown document, they will specify:
    1.  The HTTP endpoint (e.g., `POST /predict/compaction_risk`).
    2.  The structure of the JSON request body (the required inputs for the model).
    3.  The structure of the JSON response body (the model's prediction and confidence score).

---

### **Hour 3-4: Building Your First RESTful API with FastAPI & Pydantic** üöÄ

**Learning Objectives:**
* Understand the core principles of REST (Representational State Transfer).
* Build a simple but robust web API using the modern Python framework, FastAPI.
* Use Pydantic to enforce automatic data validation and generate documentation.

**Content:**
* **REST: The Workhorse of the Web**: Using standard HTTP verbs (`GET`, `POST`, `PUT`, `DELETE`) to interact with resources.
* **Why FastAPI?**: It's a high-performance framework that leverages Python type hints to provide:
    * **Incredible Speed**: comparable to NodeJS and Go.
    * **Automatic Data Validation**: Define your expected data with a **Pydantic** model, and FastAPI handles all parsing, validation, and error reporting.
    * **Interactive API Docs**: Automatically generates a Swagger UI and ReDoc for your API, which is a game-changer for developer experience.

**Hands-on Lab: "Hello, Soil API!"**
* Write a simple FastAPI application with a single `POST` endpoint at `/classify_soil`.
* Define a Pydantic model `SoilSample` that requires a `ph` (float) and `organic_matter_pct` (float).
* The endpoint will accept this `SoilSample` and return a simple JSON response like `{"classification": "High potential"}`.
* Students will then run the server and interact with the live, auto-generated Swagger documentation in their browser to test the API and see the validation errors.

---

### **Hour 5-6: Serving a Real Machine Learning Model** üß†

**Learning Objectives:**
* Load a pre-trained ML model into a FastAPI application at startup.
* Structure the application to make the model available to endpoint functions.
* Handle both synchronous and asynchronous prediction logic.

**Content:**
* **The Production ML Pattern**: The model should be loaded into memory *once* when the API server starts, not on every request. This is critical for performance.
* **FastAPI Dependency Injection**: We'll use FastAPI's elegant dependency injection system to create a `get_model` function that provides the loaded model object to our prediction endpoints.
* **Asynchronous Endpoints (`async def`)**: When is it necessary? We'll discuss the difference. For most fast, CPU-bound models, synchronous `def` is fine. For models that involve I/O (like calling another service or a slow database), `async def` is essential to prevent blocking the server.

**Practical Exercise:**
* Take a scikit-learn model trained in a previous course (e.g., a simple classifier).
* Build a FastAPI service that:
    1.  Loads the `.pkl` model file into a global variable on startup.
    2.  Provides a `/predict` endpoint that accepts the model's features in a Pydantic model.
    3.  Uses the loaded model to make a prediction.
    4.  Returns the prediction in a JSON response.

---

### **Hour 7-8: GraphQL: A Query Language for APIs** üí¨

**Learning Objectives:**
* Understand the limitations of REST, particularly over-fetching and under-fetching.
* Grasp the core concepts of GraphQL: Schemas, Queries, and Resolvers.
* Build a simple GraphQL API to serve interconnected soil data.

**Content:**
* **Beyond REST**: The problem: your mobile app needs just two fields, but the REST endpoint returns twenty (`over-fetching`). Or, to build one screen, your app has to make five different REST calls (`under-fetching`).
* **GraphQL's Solution**: The client sends a single, structured query specifying *exactly* the data it needs, and the server returns a JSON object in exactly that shape. It's a query language for your API.
* **The Three Pillars of GraphQL**:
    1.  **Schema Definition Language (SDL)**: A strongly typed way to define the data available in your API.
    2.  **Queries and Mutations**: The operations the client can perform (reading and writing data).
    3.  **Resolvers**: The functions on the server that do the work of fetching the data for each field in the schema.
* **When to Choose GraphQL**: Ideal for complex data models (like our knowledge graph from Module 17) and for applications with diverse clients (web, mobile, IoT).

**GraphQL Lab:**
* Using a Python library like **Ariadne** or **Strawberry**, you will:
    1.  Define a simple GraphQL schema for `SoilSample` and `Lab`.
    2.  Implement resolver functions that return dummy data for each type.
    3.  Use a GraphQL IDE (like the Apollo Studio Sandbox) to send queries, asking for different combinations of fields and nested data (e.g., "find a sample and the name of the lab that analyzed it").

---

### **Hour 9-10: Production Hardening I: Authentication & Authorization** üîê

**Learning Objectives:**
* Secure API endpoints to prevent unauthorized access.
* Implement both simple API Key and robust OAuth2/JWT authentication.
* Design a simple Role-Based Access Control (RBAC) system.

**Content:**
* **Authentication (Who are you?)**:
    * **API Keys**: Simple secret tokens passed in a header (`X-API-Key`). Good for machine-to-machine communication.
    * **OAuth2 & JWTs**: The standard for user-facing applications. The user logs in once, gets a signed, short-lived JSON Web Token (JWT), and includes it in the `Authorization` header of subsequent requests.
* **Authorization (What are you allowed to do?)**:
    * **Role-Based Access Control (RBAC)**: We'll design a system using FastAPI's dependency injection where a request's token is decoded to determine the user's role (e.g., `farmer`, `agronomist`, `researcher`). Endpoints can then require a specific role to be accessed.

**Security Lab:**
* Take the model-serving FastAPI app from Hour 6.
* Implement API key authentication. Write a dependency function that checks for a valid key in the request headers and raises a `401 Unauthorized` error if it's missing or invalid.
* Create two API keys, one for a `farmer` role and one for a `researcher` role. Create two endpoints, where one is only accessible to the `researcher`.

---

### **Hour 11-12: Production Hardening II: Rate Limiting & Usage Tracking** üö¶

**Learning Objectives:**
* Protect the API from abuse and ensure fair usage with rate limiting.
* Implement a usage tracking system for billing and analytics.
* Understand different rate limiting algorithms like token bucket.

**Content:**
* **Preventing Denial of Service**: A single buggy or malicious client could overwhelm your service with requests, making it unavailable for everyone. Rate limiting is the primary defense.
* **The Token Bucket Algorithm**: A classic and effective rate limiting strategy. Each user has a "bucket" of tokens that refills at a constant rate. Each request consumes a token. If the bucket is empty, the request is rejected with a `429 Too Many Requests` error.
* **Usage Tracking for Business Logic**: For our service to be viable, we need to know who is using it and how much. We'll implement a simple "middleware" that logs key information about every successful request (API key, timestamp, endpoint called) to a database or log file. This data is the foundation for a billing or quota system.

**Hands-on Lab:**
* Using the `slowapi` library with FastAPI, add a rate limit to your secured `/predict` endpoint (e.g., "10 requests per minute per API key").
* Write a simple client script that calls the API in a loop and demonstrate that it starts receiving `429` error codes after the limit is reached.
* Add a logging middleware to the FastAPI app that prints a structured log message for every request, capturing the client's IP and API key.

---

### **Hour 13-14: Deployment & Observability with Kubernetes** üö¢

**Learning Objectives:**
* Package a FastAPI application into a Docker container.
* Deploy the containerized API to a Kubernetes cluster.
* Add basic observability (logging, metrics) to the deployed service.

**Content:**
* **Containerizing the API**: Writing a `Dockerfile` that sets up the Python environment, copies the application code, and uses a production-grade server like **Uvicorn** with **Gunicorn** workers to run the app.
* **Deploying to Kubernetes**:
    * **`Deployment`**: To manage the replicas of our API pods.
    * **`Service`**: To provide a stable internal IP address for the pods.
    * **`Ingress`**: To expose the service to the public internet with a proper hostname.
* **Observability**:
    * **Structured Logging**: Configuring our app to output logs as JSON, which makes them easy to search and analyze in a central logging system.
    * **Metrics with Prometheus**: Adding a client library to our FastAPI app to expose key metrics (request counts, latencies, error rates) on a `/metrics` endpoint that Prometheus can scrape.

**Deployment Lab:**
* Take your secure, rate-limited FastAPI application and write a `Dockerfile` for it.
* Write a `deployment.yaml` and a `service.yaml`.
* Deploy the application to a local Kubernetes cluster (Minikube).
* Use `kubectl port-forward` to access the service from your local machine and verify that it is running correctly inside the cluster.

---

### **Hour 15: Capstone: Building a Production-Ready Soil Intelligence Service** üèÜ

**Final Challenge:**
You are tasked with deploying a complete, production-ready version of the `NitrogenCycler` foundation model as a web service. This service will be used by third-party farm management software to get real-time nitrogen mineralization predictions.

**Your Mission:**
1.  **Build the API**: Using FastAPI and Pydantic, create a `/predict/nitrogen_mineralization` endpoint. The API should accept relevant soil properties (SOC, pH, temperature, moisture) and return a predicted mineralization rate and a confidence score.
2.  **Implement Production-Grade Features**:
    * **Authentication**: The service must be secured with bearer token (JWT) authentication. You will create a simple `/token` endpoint that issues tokens for valid users.
    * **Authorization**: Create two roles, `standard_user` and `premium_user`, decoded from the JWT.
    * **Rate Limiting**: `standard_user`s are limited to 100 requests per day. `premium_user`s have a higher limit of 5,000 requests per day.
    * **Usage Tracking**: Every successful prediction request must be logged with the user ID and timestamp to a structured log file.
3.  **Containerize and Deploy**: Provide a `Dockerfile` and the necessary Kubernetes manifests (`Deployment`, `Service`, `Ingress`) to deploy the service.
4.  **Create Client-Facing Documentation**: Ensure the FastAPI application has excellent metadata so the auto-generated Swagger UI is a complete, professional, and interactive guide for a developer who wants to use your API.
5.  **Write an Integration Test**: Create a Python script that simulates a client application. It must:
    a.  First, call the `/token` endpoint to get a JWT.
    b.  Then, use that token to successfully call the `/predict` endpoint.
    c.  Demonstrate that a request without a token fails.

**Deliverables:**
* A Git repository containing the complete, documented FastAPI application.
* The `Dockerfile` and all Kubernetes YAML files.
* The Python integration test script.
* A short markdown document that serves as a "Quick Start" guide for a new developer, directing them to the interactive API documentation and explaining the authentication flow.

**Assessment Criteria:**
* The correctness and robustness of the API implementation.
* The successful and correct implementation of all production features (Auth, RBAC, Rate Limiting).
* The quality and completeness of the container and deployment configurations.
* The professionalism and clarity of the auto-generated and written documentation.